{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23c9e2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "import heapq\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fc044d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_density_v3(G, S, T):\n",
    "    if G.number_of_edges() == 0:\n",
    "        return 0\n",
    "    probability_sum = sum(G[u][v]['weight'] * G[u][v]['probability'] for u, v in G.edges() if u in S and v in T)\n",
    "    return probability_sum / (len(S) * len(T))**0.5\n",
    "\n",
    "\n",
    "def plot_graph_v2(G):\n",
    "    pos = nx.spring_layout(G)  # Tạo bố cục cho đồ thị\n",
    "\n",
    "    # Lấy thuộc tính xác suất và trọng số của các cạnh\n",
    "    edge_probabilities = nx.get_edge_attributes(G, 'probability')\n",
    "    edge_weights = nx.get_edge_attributes(G, 'weight')\n",
    "\n",
    "    # Kết hợp xác suất và trọng số vào nhãn cạnh\n",
    "    edge_labels = {edge: f\"{edge_weights[edge]:.2f}, {edge_probabilities[edge]:.2f}\" for edge in G.edges()}\n",
    "\n",
    "    # Vẽ đồ thị\n",
    "    nx.draw(G, pos, with_labels=True, node_color='lightblue', edge_color='red', node_size=200, font_size=8, font_weight='bold')\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=7)  # Hiển thị nhãn của các cạnh\n",
    "\n",
    "    plt.title('Uncertain Weighted Directed Graph Visualization')\n",
    "    plt.show()\n",
    "    \n",
    "def average_edge_probability(G):\n",
    "    \"\"\" Tính xác suất trung bình của các cạnh trong đồ thị G. \"\"\"\n",
    "    total_probability = sum(nx.get_edge_attributes(G, 'probability').values())\n",
    "    num_edges = G.number_of_edges()\n",
    "    return total_probability / num_edges if num_edges > 0 else 0\n",
    "\n",
    "\n",
    "\n",
    "def calculate_f_beta_v3(G_S, beta, S, T):\n",
    "    num_edges = G_S.number_of_edges()    \n",
    "    if len(S) > 0 and len(T) > 0:\n",
    "        f_beta = (weighted_average_edge_probability(G_S) - beta) * (num_edges / (len(S) * len(T))**0.5)\n",
    "    else:\n",
    "        f_beta = 0\n",
    "    return f_beta\n",
    "    \n",
    "\n",
    "def weighted_average_edge_probability(G):\n",
    "    total_weighted_probability = sum(G[u][v]['weight'] * G[u][v]['probability'] for u, v in G.edges())  \n",
    "    num_edges = G.number_of_edges()\n",
    "    return total_weighted_probability / num_edges if num_edges > 0 else 0\n",
    "\n",
    "def surplus_degree_out(G, v, beta):\n",
    "    return sum(G[v][w]['weight'] *G[v][w]['probability'] - beta for w in G.successors(v) if w in G)\n",
    "\n",
    "def surplus_degree_in(G, v, beta):\n",
    "    return sum(G[u][v]['weight'] *G[u][v]['probability'] - beta for u in G.predecessors(v) if u in G)\n",
    "\n",
    "\n",
    "def initialize_priority_queue_out(G, beta):\n",
    "    \"\"\" Khởi tạo hàng đợi ưu tiên với bậc dư thừa cho mỗi đỉnh \"\"\"\n",
    "    priority_queue = []\n",
    "    for v in G.nodes():\n",
    "        sd = surplus_degree_out(G, v, beta)\n",
    "        heapq.heappush(priority_queue, (sd, v))\n",
    "        \n",
    "    return priority_queue\n",
    "\n",
    "def initialize_priority_queue_in(G, beta):\n",
    "    \"\"\" Khởi tạo hàng đợi ưu tiên với bậc dư thừa cho mỗi đỉnh \"\"\"\n",
    "    priority_queue = []\n",
    "    for v in G.nodes():\n",
    "        sd = surplus_degree_in(G, v, beta)\n",
    "        heapq.heappush(priority_queue, (sd, v))\n",
    "        \n",
    "    return priority_queue\n",
    "\n",
    "\n",
    "def calculate_edge_density_v3(G):\n",
    "    \"\"\"Tính mật độ cạnh kỳ vọng của đồ thị G. τ\"\"\"\n",
    "    num_vertices = len(G.nodes())\n",
    "    num_possible_edges = num_vertices * (num_vertices - 1) if num_vertices > 1 else 1\n",
    "    sum_weighted_probabilities = sum(G[u][v]['weight'] * G[u][v]['probability'] for u, v in G.edges())\n",
    "    return sum_weighted_probabilities / num_possible_edges\n",
    "\n",
    "def expected_density_v3(G, S, T):\n",
    "    if G.number_of_edges() == 0:\n",
    "        return 0\n",
    "    probability_sum = sum(G[u][v]['weight'] * G[u][v]['probability'] for u, v in G.edges() if u in S and v in T)\n",
    "    return probability_sum / (len(S) * len(T))**0.5\n",
    "\n",
    "def trong_so_trung_binh_canh(G):\n",
    "    \"\"\" Tính xác suất trung bình của các cạnh trong đồ thị G. \"\"\"\n",
    "    total_probability = sum(nx.get_edge_attributes(G, 'weight').values())\n",
    "    num_edges = G.number_of_edges()\n",
    "    return total_probability / num_edges if num_edges > 0 else 0\n",
    "def update_priority_queue_in(H, beta, neighbors, priority_queue_in):\n",
    "    for neighbor in neighbors:\n",
    "        if neighbor in H:\n",
    "            sd_in = surplus_degree_in(H, neighbor, beta)\n",
    "            heapq.heappush(priority_queue_in, (sd_in, neighbor))\n",
    "\n",
    "def update_priority_queue_out(H, beta, neighbors, priority_queue_out):\n",
    "    for neighbor in neighbors:\n",
    "        if neighbor in H:\n",
    "            sd_out = surplus_degree_out(H, neighbor, beta)\n",
    "            heapq.heappush(priority_queue_out, (sd_out, neighbor))\n",
    "\n",
    "        \n",
    "\n",
    "def greedy_average_surplus_degree(G, beta, S, T, c):\n",
    "    H = G.copy()\n",
    "    S_temp = S\n",
    "    T_temp = T\n",
    "    best_subgraph = H.copy()\n",
    "    best_f_beta = calculate_f_beta_v3(best_subgraph, beta, S_temp, T_temp)\n",
    "\n",
    "\n",
    "    num_iterations = len(S_temp) + len(T_temp)  # Tổng số đỉnh ban đầu trong cả hai tập\n",
    "    with tqdm(total=num_iterations, desc=\"Processing\", unit=\"node\") as pbar:\n",
    "        while S_temp and T_temp:\n",
    "            i_min = min(S_temp, key=lambda i: surplus_degree_out(H, i, beta))\n",
    "            d_S = surplus_degree_out(H, i_min, beta)\n",
    "\n",
    "            j_min = min(T_temp, key=lambda j: surplus_degree_in(H, j, beta))\n",
    "            d_T = surplus_degree_in(H, j_min, beta)\n",
    "        \n",
    "            \n",
    "            if c * d_S <= d_T / c:\n",
    "                # Loại bỏ i_min khỏi S_temp, nhưng giữ lại trong T_temp nếu có\n",
    "                S_temp.remove(i_min)\n",
    "                if i_min not in T_temp:  # Nếu i_min không có trong T_temp, loại nó khỏi đồ thị\n",
    "                    H.remove_node(i_min)\n",
    "                else:\n",
    "                    # Nếu i_min vẫn còn trong T_temp, chỉ loại bỏ các cạnh đi ra từ i_min\n",
    "                    for w in list(H.successors(i_min)):\n",
    "                        if w in T_temp:\n",
    "                            H.remove_edge(i_min, w)\n",
    "            else:\n",
    "                # Loại bỏ j_min khỏi T_temp, nhưng giữ lại trong S_temp nếu có\n",
    "                T_temp.remove(j_min)\n",
    "                if j_min not in S_temp:  # Nếu j_min không có trong S_temp, loại nó khỏi đồ thị\n",
    "                    H.remove_node(j_min)\n",
    "                else:\n",
    "                    # Nếu j_min vẫn còn trong S_temp, chỉ loại bỏ các cạnh đi vào j_min\n",
    "                    for u in list(H.predecessors(j_min)):\n",
    "                        if u in S_temp:\n",
    "                            H.remove_edge(u, j_min)\n",
    "\n",
    "            current_f_beta = calculate_f_beta_v3(H, beta, S_temp, T_temp)\n",
    "            \n",
    "            S_temp = {u for u in S_temp if u in H}\n",
    "            T_temp = {v for v in T_temp if v in H}\n",
    "            \n",
    "            if current_f_beta > best_f_beta:\n",
    "                best_f_beta = current_f_beta\n",
    "                best_subgraph = H.copy()  # Lưu bản sao của H với mật độ cao nhất\n",
    "\n",
    "            \n",
    "            pbar.update(1)  # Cập nhật tiến trình mỗi khi một đỉnh được loại bỏ\n",
    "    \n",
    "    return best_subgraph\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "544952b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 3085\n",
      "Number of edges: 314788\n",
      "Giá trị cạnh trung bình của đồ thị protein579138: 0.28146895688526885\n",
      "Độ lệch chuẩn của của  đồ thị protein579138: 0.18211671967697324\n",
      "Độ lệch chuẩn trọng số của của  đồ thị protein579138: 0.14835576350857846\n",
      "Trọng số cạnh trung bình của đồ thị là: 0.05057740498418036\n",
      "Mật độ kì cạnh vọng của thuật toán obs  là: 0.0009661932566591212\n"
     ]
    }
   ],
   "source": [
    "random.seed(9)\n",
    "# Đọc dữ liệu từ tệp TXT\n",
    "file_path = '/teamspace/uploads/data/1736402.protein.links.full.v12.0.txt.gz'\n",
    "data = pd.read_csv(file_path, sep=' ')\n",
    "\n",
    "# Khởi tạo đồ thị có hướng\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Tìm trọng số lớn nhất trong cột 'experiments'\n",
    "max_experiment_weight = data['experiments_transferred'].max()\n",
    "\n",
    "# Thêm các cạnh với trọng số và xác suất\n",
    "for _, row in data.iterrows():\n",
    "    protein1 = row['protein1']\n",
    "    protein2 = row['protein2']\n",
    "    experiment_weight = row['experiments_transferred']\n",
    "\n",
    "    # Tính tỷ lệ trọng số so với trọng số lớn nhất\n",
    "    if max_experiment_weight > 0:\n",
    "        normalized_weight = experiment_weight / max_experiment_weight\n",
    "    else:\n",
    "        normalized_weight = 0  # Tránh chia cho 0 trong trường hợp không có trọng số nào\n",
    "\n",
    "    # Giả sử xác suất được tính dựa trên combined_score\n",
    "    combined_score = row['combined_score']\n",
    "    probability = combined_score / 1000.0  # Điều chỉnh hệ số nếu cần thiết\n",
    "\n",
    "    # Định hướng cạnh dựa trên một quy tắc ngẫu nhiên\n",
    "    if random.choice([True, False]):\n",
    "        G.add_edge(protein1, protein2, probability=probability, weight=normalized_weight)  \n",
    "        \n",
    "S = set()\n",
    "T = set()\n",
    "for u, v in G.edges():\n",
    "    S.add(u)\n",
    "    T.add(v)\n",
    "# print(\"tập S có:\",len(S))\n",
    "# print(\"tập T có:\",len(T))\n",
    "\n",
    "print(\"Number of nodes:\", G.number_of_nodes())\n",
    "print(\"Number of edges:\", G.number_of_edges())\n",
    "\n",
    "\n",
    "# Lấy các giá trị xác suất từ các cạnh\n",
    "probabilities = [G[u][v]['probability'] for u, v in G.edges()]\n",
    "weights = [G[u][v]['weight'] for u, v in G.edges()]\n",
    "# Tính giá trị trung bình\n",
    "mean_probability = np.mean(probabilities)\n",
    "mean_weight = np.mean(weights)\n",
    "do_lech_chuan_trong_so = np.std(weights)\n",
    "\n",
    "\n",
    "# Tính độ lệch chuẩn\n",
    "std_deviation = np.std(probabilities)\n",
    "\n",
    "    \n",
    "print(\"Giá trị cạnh trung bình của đồ thị protein579138:\", mean_probability)\n",
    "print(\"Độ lệch chuẩn của của  đồ thị protein579138:\", std_deviation)\n",
    "print(\"Độ lệch chuẩn trọng số của của  đồ thị protein579138:\", do_lech_chuan_trong_so)\n",
    "\n",
    "print(\"Trọng số cạnh trung bình của đồ thị là:\",mean_weight)\n",
    "print(\"Mật độ kì cạnh vọng của thuật toán obs  là:\",calculate_edge_density_v3(G))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6202e67b-3a5b-46ea-b0f4-c91323c50c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|█████████▉| 6123/6124 [54:06<00:00,  1.89node/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mật độ kì vọng của đồ thị con do thuật toán obs sinh ra là: 30.439996003485977\n",
      "Số đỉnh trong đồ thị con của thuật toán obs  là: 106\n",
      "Số cạnh trong đồ thị con của thuật toán obs  là: 4294\n",
      "Mật độ kì cạnh vọng của thuật toán obs  là: 0.26648578056942834\n",
      "Xác xuất cạnh trung bình của thuật toán obs là: 0.8632899394503913\n",
      " trọng số cạnh trung bình của thuật toán obs là: 0.750118073359806\n",
      "Độ lệch chuẩn xác xuất: 0.1934200597702181\n",
      "Độ lệch chuẩn trọng số: 0.2606746014207703\n",
      "Trung bình trọng số xác xuất : 0.690728164354387\n"
     ]
    }
   ],
   "source": [
    "beta = 0.2 * 0.2\n",
    "c = len(S) / len(T)\n",
    "ObsEmailEuCore01 = greedy_average_surplus_degree(G,beta, S, T, c)\n",
    "# Xác định các tập S và T từ các cạnh của đồ thị\n",
    "S = set()\n",
    "T = set()\n",
    "for u, v in ObsEmailEuCore01.edges():\n",
    "    S.add(u)\n",
    "    T.add(v)\n",
    "\n",
    "# Lấy các giá trị xác suất từ các cạnh\n",
    "probabilities = [ObsEmailEuCore01[u][v]['probability'] for u, v in ObsEmailEuCore01.edges()]\n",
    "weights = [ObsEmailEuCore01[u][v]['weight'] for u, v in ObsEmailEuCore01.edges()]\n",
    "\n",
    "# Tính giá trị trung bình\n",
    "mean_probability = np.mean(probabilities)\n",
    "mean_weight = np.mean(weights)\n",
    "\n",
    "# Tính độ lệch chuẩn\n",
    "std_deviation = np.std(probabilities)\n",
    "std_weight= np.std(weights)\n",
    "print(\"Mật độ kì vọng của đồ thị con do thuật toán obs sinh ra là:\", expected_density_v3(ObsEmailEuCore01, S, T))\n",
    "print(\"Số đỉnh trong đồ thị con của thuật toán obs  là:\", ObsEmailEuCore01.number_of_nodes())\n",
    "print(\"Số cạnh trong đồ thị con của thuật toán obs  là:\", ObsEmailEuCore01.number_of_edges())\n",
    "print(\"Mật độ kì cạnh vọng của thuật toán obs  là:\",calculate_edge_density_v3(ObsEmailEuCore01))\n",
    "print(\"Xác xuất cạnh trung bình của thuật toán obs là:\",average_edge_probability(ObsEmailEuCore01))\n",
    "print(\" trọng số cạnh trung bình của thuật toán obs là:\",mean_weight)\n",
    "print(\"Độ lệch chuẩn xác xuất:\", std_deviation)\n",
    "print(\"Độ lệch chuẩn trọng số:\", std_weight)\n",
    "print(\"Trung bình trọng số xác xuất :\",weighted_average_edge_probability(ObsEmailEuCore01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c62fe09a-1a6d-40ed-82d1-c55bda327ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(ObsEmailEuCore01, \"Obs_1736402_02.gexf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5bbb1c-1ce5-4e72-af0e-4d135d69e373",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
